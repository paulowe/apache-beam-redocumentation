{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79af78f2",
   "metadata": {},
   "source": [
    "### 1. Apache Beam WordCount Example\n",
    "Key concept this notebook covers:\n",
    "- Creating the pipeline\n",
    "- Applying transforms to the pipeline\n",
    "- Reading input (text files in this example)\n",
    "- Applying ParDo transforms\n",
    "- Applying SDK provided transforms (in this example count)\n",
    "- Writing output (in this case, to a text file)\n",
    "- Running the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36850525",
   "metadata": {},
   "source": [
    "#### 1.1 MinimalWordCount\n",
    "\n",
    "MinimalWordCount demonstrates a simple pipeline that uses the Direct Runner to read from a text file, apply transforms to tokenize and count the words, and write the data to an output text file\n",
    "\n",
    "#### 1.2 Creating the pipeleine\n",
    "Create a `PipelineOptions` object. This object lets us set various options for our pipeline, such as the runner that will execute our pipeline and any runner specific configuration required.\n",
    "\n",
    "Note: In this example we set these options programmatically, but more often, command-line arguments are used to set PipelineOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b6aafe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run and print a shell command.\n",
    "def run(cmd):\n",
    "  print('>> {}'.format(cmd))\n",
    "  !{cmd}\n",
    "  print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a19af7e-8bf2-48ea-aa52-9e146e29ee8b",
   "metadata": {},
   "source": [
    "### 2. Set up and Installation\n",
    "Make sure it is in your expected environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8186f997-603d-4adc-ab14-fd3551054a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install apache-beam.\n",
    "run('pip install --quiet apache-beam')\n",
    "\n",
    "# Copy the input file into the local file system.\n",
    "run('mkdir -p data')\n",
    "# run('gsutil cp gs://dataflow-samples/shakespeare/kinglear.txt data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b7a2aa-e537-46b3-a1d3-fdfb94bc5a13",
   "metadata": {},
   "source": [
    "##### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7070aac6-5bb1-49f1-9984-e541412af266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.options.pipeline_options import PipelineOptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9edf43-a5c6-45ca-9b6c-0ab7ed804abb",
   "metadata": {},
   "source": [
    "### 3. Data processing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b57a94-79f5-4cb9-9fab-fa60f949bdde",
   "metadata": {},
   "source": [
    "#### 3.1 Configure Pipeline Options object\n",
    "PieplineOptions is a container that passes in your command line arguments\n",
    "\n",
    "https://beam.apache.org/releases/pydoc/2.5.0/apache_beam.options.pipeline_options.html#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a58867a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Public File in GCS\n",
    "input_file = 'data/inputs/file1.txt'\n",
    "output_path = 'data/outputs/'\n",
    "# Configure dataflow runner\n",
    "beam_options = PipelineOptions(\n",
    "    runner='DirectRunner',\n",
    "    job_name='unique-job-name-processfile',\n",
    "    temp_location='data/temp',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b7d434-44fd-425f-8d50-0275b1777c0f",
   "metadata": {},
   "source": [
    "#### 3.2 Create Pipeline Object\n",
    "The next step is to create a Pipeline object with the options weâ€™ve just constructed. \n",
    "\n",
    "The Pipeline object builds up the graph of transformations to be executed, associated with that particular pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "427a05f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = beam.Pipeline(options=beam_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a1bcba-11e3-4735-a217-cc1aa5981cb1",
   "metadata": {},
   "source": [
    "#### 3.3 Transformations. - Applying pipeline transforms\n",
    "The MinimalWordCount pipeline contains several transforms to read data into the pipeline, manipulate or otherwise transform the data and write out the results\n",
    "\n",
    "Transforms can consist of an individual operation, or can contain multiple nested transforms\n",
    "\n",
    "Each transform takes some kind of input data and produces some output data. The input and output data is often represented by the SDK class PCollection. \n",
    "\n",
    "**PCollection** is a special class, provided by the Beam SDK, that you can use to represent a dataset of virtually any size, including unbounded datasets\n",
    "\n",
    "<img src='https://beam.apache.org/images/wordcount-pipeline.svg' />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d65908-59a8-472c-bb56-176877899715",
   "metadata": {},
   "source": [
    "#### 3.4 Transformations in MinimalWordCount Solution\n",
    "The MinimalWordCount pipeline contains 5 transforms:\n",
    "#### 3.4.1 Read Transform is applied to the pipeline object itsef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e0c0f33-e1e0-44af-884f-24890f1a150e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-b078645a26e6>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-b078645a26e6>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    | beam.io.ReadFromText(input_file)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pipeline\n",
    "| beam.io.ReadFromText(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bbd45c-1ef0-4c2b-bec6-0625e3c4f0a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
